diff --git a/src/main/ii.go b/src/main/ii.go
index 6e38b2a..66f9b4d 100644
--- a/src/main/ii.go
+++ b/src/main/ii.go
@@ -1,8 +1,13 @@
 package main
 
-import "os"
-import "fmt"
-import "mapreduce"
+import (
+	"fmt"
+	"mapreduce"
+	"os"
+	"sort"
+	"strings"
+	"unicode"
+)
 
 // The mapping function is called once for each piece of the input.
 // In this framework, the key is the name of the file that is being processed,
@@ -10,6 +15,18 @@ import "mapreduce"
 // key/value pairs, each represented by a mapreduce.KeyValue.
 func mapF(document string, value string) (res []mapreduce.KeyValue) {
 	// Your code here (Part V).
+	f := func(c rune) bool {
+		return !unicode.IsLetter(c)
+	}
+	words := strings.FieldsFunc(value, f)
+	set := make(map[string]bool, 0)
+	for _, word := range words {
+		set[word] = true
+	}
+	for word, _ := range set {
+		res = append(res, mapreduce.KeyValue{word, document})
+	}
+	return
 }
 
 // The reduce function is called once for each key generated by Map, with a
@@ -17,6 +34,8 @@ func mapF(document string, value string) (res []mapreduce.KeyValue) {
 // should be a single output value for that key.
 func reduceF(key string, values []string) string {
 	// Your code here (Part V).
+	sort.Strings(values)
+	return fmt.Sprintf("%d %s", len(values), strings.Join(values, ","))
 }
 
 // Can be run in 3 ways:
diff --git a/src/main/wc.go b/src/main/wc.go
index e9afedf..dedde9f 100644
--- a/src/main/wc.go
+++ b/src/main/wc.go
@@ -4,6 +4,9 @@ import (
 	"fmt"
 	"mapreduce"
 	"os"
+	"strconv"
+	"strings"
+	"unicode"
 )
 
 //
@@ -15,6 +18,15 @@ import (
 //
 func mapF(filename string, contents string) []mapreduce.KeyValue {
 	// Your code here (Part II).
+	f := func(c rune) bool {
+		return !unicode.IsLetter(c)
+	}
+	words := strings.FieldsFunc(contents, f)
+	var res []mapreduce.KeyValue
+	for _, word := range words {
+		res = append(res, mapreduce.KeyValue{word, ""})
+	}
+	return res
 }
 
 //
@@ -24,6 +36,7 @@ func mapF(filename string, contents string) []mapreduce.KeyValue {
 //
 func reduceF(key string, values []string) string {
 	// Your code here (Part II).
+	return strconv.Itoa(len(values))
 }
 
 // Can be run in 3 ways:
diff --git a/src/mapreduce/common_map.go b/src/mapreduce/common_map.go
index 6f596fa..e13798d 100644
--- a/src/mapreduce/common_map.go
+++ b/src/mapreduce/common_map.go
@@ -1,7 +1,10 @@
 package mapreduce
 
 import (
+	"encoding/json"
 	"hash/fnv"
+	"io/ioutil"
+	"os"
 )
 
 func doMap(
@@ -53,6 +56,26 @@ func doMap(
 	//
 	// Your code here (Part I).
 	//
+	content, _ := ioutil.ReadFile(inFile)
+	result := mapF(inFile, string(content))
+	buckets := make([][]KeyValue, nReduce)
+	for i := 0; i < nReduce; i++ {
+		buckets[i] = make([]KeyValue, 0, 128)
+	}
+	for _, kv := range result {
+		k := kv.Key
+		buckets[ihash(k)%nReduce] = append(buckets[ihash(k)%nReduce], kv)
+	}
+	for i := 0; i < nReduce; i++ {
+		output_name := reduceName(jobName, mapTask, i)
+		output_file, _ := os.Create(output_name)
+		enc := json.NewEncoder(output_file)
+		for _, kv := range buckets[i] {
+			enc.Encode(&kv)
+		}
+		output_file.Close()
+	}
+
 }
 
 func ihash(s string) int {
diff --git a/src/mapreduce/common_reduce.go b/src/mapreduce/common_reduce.go
index c0ea099..a6b0074 100644
--- a/src/mapreduce/common_reduce.go
+++ b/src/mapreduce/common_reduce.go
@@ -1,5 +1,10 @@
 package mapreduce
 
+import (
+	"encoding/json"
+	"os"
+)
+
 func doReduce(
 	jobName string, // the name of the whole MapReduce job
 	reduceTask int, // which reduce task this is
@@ -44,4 +49,28 @@ func doReduce(
 	//
 	// Your code here (Part I).
 	//
+	data := make(map[string][]string)
+	for i := 0; i < nMap; i++ {
+		input_name := reduceName(jobName, i, reduceTask)
+		input_file, _ := os.Open(input_name)
+		dec := json.NewDecoder(input_file)
+		var kv KeyValue
+		for err := dec.Decode(&kv); err == nil; err = dec.Decode(&kv) {
+			if data[kv.Key] == nil {
+				data[kv.Key] = []string{kv.Value}
+			} else {
+				data[kv.Key] = append(data[kv.Key], kv.Value)
+			}
+		}
+		input_file.Close()
+	}
+	output_name := mergeName(jobName, reduceTask)
+	output_file, _ := os.Create(output_name)
+	enc := json.NewEncoder(output_file)
+	for k, v := range data {
+		kv := KeyValue{k, reduceF(k, v)}
+		enc.Encode(&kv)
+	}
+	output_file.Close()
+
 }
diff --git a/src/mapreduce/schedule.go b/src/mapreduce/schedule.go
index 1d8dfa8..292cbb6 100644
--- a/src/mapreduce/schedule.go
+++ b/src/mapreduce/schedule.go
@@ -1,6 +1,9 @@
 package mapreduce
 
-import "fmt"
+import (
+	"fmt"
+	"sync/atomic"
+)
 
 //
 // schedule() starts and waits for all tasks in the given phase (mapPhase
@@ -30,5 +33,59 @@ func schedule(jobName string, mapFiles []string, nReduce int, phase jobPhase, re
 	//
 	// Your code here (Part III, Part IV).
 	//
+	tasks := make(chan DoTaskArgs, ntasks)
+	for i := 0; i < ntasks; i++ {
+		switch phase {
+		case mapPhase:
+			tasks <- DoTaskArgs{jobName, mapFiles[i], phase, i, n_other}
+		case reducePhase:
+			tasks <- DoTaskArgs{jobName, "", phase, i, n_other}
+		}
+	}
+	workers := []string{}
+	numGoroutineFinished := uint32(0)
+	numTaskFinished := uint32(0)
+	one_task_done := make(chan bool)
+	all_task_done := make(chan bool)
+	go_done := make(chan bool)
+	finish := false
+	for !finish {
+		select {
+		case worker := <-registerChan:
+			workers = append(workers, worker)
+			go func(worker string) {
+				for {
+					select {
+					case task := <-tasks:
+						ok := call(worker, "Worker.DoTask", task, nil)
+						if !ok {
+							tasks <- task
+						} else {
+							one_task_done <- true
+						}
+					case <-all_task_done:
+						go_done <- true
+						return
+					}
+				}
+			}(worker)
+		case <-go_done:
+			atomic.AddUint32(&numGoroutineFinished, 1)
+			if atomic.LoadUint32(&numGoroutineFinished) == uint32(len(workers)) {
+				finish = true
+			}
+		case <-one_task_done:
+			atomic.AddUint32(&numTaskFinished, 1)
+			if atomic.LoadUint32(&numTaskFinished) == uint32(ntasks) {
+				for i := 0; i < len(workers); i++ {
+					all_task_done <- true
+				}
+			}
+		}
+	}
+	close(tasks)
+	close(one_task_done)
+	close(all_task_done)
+
 	fmt.Printf("Schedule: %v done\n", phase)
 }
